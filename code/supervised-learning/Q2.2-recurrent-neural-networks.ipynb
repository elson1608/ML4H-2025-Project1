{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Specify whether you want to use a bidirectional or unidirectional LSTM\n",
    "bidirectional = True    \n",
    "\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)  # Sets the seed for CPU operations\n",
    "    torch.cuda.manual_seed(seed)  # Sets the seed for CUDA GPU operations\n",
    "    torch.cuda.manual_seed_all(seed)  # If using multiple GPUs\n",
    "    random.seed(seed)  # Python's random library\n",
    "    np.random.seed(seed)  # NumPy\n",
    "    \n",
    "    # For determinism in certain CUDA operations\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "df_a = pd.read_parquet('../../data/set-a-imputed-scaled.parquet').sort_values(by=['RecordID','Time'])\n",
    "df_b = pd.read_parquet('../../data/set-b-imputed-scaled.parquet').sort_values(by=['RecordID','Time'])\n",
    "df_c = pd.read_parquet('../../data/set-c-imputed-scaled.parquet').sort_values(by=['RecordID','Time'])\n",
    "\n",
    "\n",
    "# Get labels\n",
    "outcomes_a = pd.read_csv('../../data/Outcomes-a.txt').sort_values(by=['RecordID'])[['RecordID', 'In-hospital_death']]\n",
    "outcomes_b = pd.read_csv('../../data/Outcomes-b.txt').sort_values(by=['RecordID'])[['RecordID', 'In-hospital_death']]\n",
    "outcomes_c = pd.read_csv('../../data/Outcomes-c.txt').sort_values(by=['RecordID'])[['RecordID', 'In-hospital_death']]\n",
    "\n",
    "\n",
    "# Drop time\n",
    "df_a = df_a.drop(columns=['Time'])\n",
    "df_b = df_b.drop(columns=['Time'])\n",
    "df_c = df_c.drop(columns=['Time'])\n",
    "\n",
    "\n",
    "# Group by 'Category'\n",
    "df_a = df_a.groupby('RecordID')\n",
    "df_b = df_b.groupby('RecordID')\n",
    "df_c = df_c.groupby('RecordID')\n",
    "\n",
    "# Convert groups into stacked tensor (dropping the group column dynamically)\n",
    "X_train = torch.stack([torch.tensor(group.drop(columns='RecordID').values, dtype=torch.float32) for _, group in df_a])  # Stack into a 3D tensor\n",
    "X_val = torch.stack([torch.tensor(group.drop(columns='RecordID').values, dtype=torch.float32) for _, group in df_b])\n",
    "X_test = torch.stack([torch.tensor(group.drop(columns='RecordID').values, dtype=torch.float32) for _, group in df_c])  \n",
    "\n",
    "y_train = torch.tensor(outcomes_a.drop(columns=['RecordID']).values, dtype=torch.float32)\n",
    "y_val = torch.tensor(outcomes_b.drop(columns=['RecordID']).values, dtype=torch.float32)\n",
    "y_test = torch.tensor(outcomes_c.drop(columns=['RecordID']).values, dtype=torch.float32)\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
    "val_dataset = TensorDataset(torch.Tensor(X_val), torch.Tensor(y_val))\n",
    "test_dataset = TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM classifier\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, num_layers, num_classes, dropout, bidirectional):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        if bidirectional:\n",
    "            hidden_size = hidden_size * 2\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_dim)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # We only want the output from the last time step\n",
    "        last_time_step_out = lstm_out[:, -1, :]\n",
    "        out = self.fc(last_time_step_out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "     hidden_size = trial.suggest_categorical(\"hidden_size\", [64, 128, 256]) \n",
    "     num_layers = trial.suggest_categorical(\"num_layers\", [1, 2, 4, 8])\n",
    "     learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True) # Learning rate\n",
    "     weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)  # Weight decay\n",
    "     dropout = trial.suggest_float('dropout', 0.1, 0.75)  # Weight decay\n",
    "\n",
    "\n",
    "     model = LSTMClassifier(\n",
    "          input_dim=41, \n",
    "          hidden_size=hidden_size, \n",
    "          num_layers=num_layers, \n",
    "          num_classes=1, \n",
    "          dropout=dropout, \n",
    "          bidirectional=bidirectional\n",
    "     ).to(device)\n",
    "\n",
    "\n",
    "     optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "     criterion = nn.BCELoss()\n",
    "\n",
    "     best_val_score = 0.0\n",
    "     for epoch in range(num_epochs):\n",
    "          model.train()\n",
    "          for inputs, targets in train_loader:\n",
    "              inputs, targets = inputs.to(device), targets.to(device)\n",
    "              optimizer.zero_grad()\n",
    "              outputs = model(inputs)\n",
    "              loss = criterion(outputs.squeeze(), targets.squeeze())\n",
    "              loss.backward()\n",
    "              optimizer.step()\n",
    "\n",
    "          # Validation loop\n",
    "          model.eval()\n",
    "          all_val_targets = []\n",
    "          all_val_predictions = []\n",
    "          with torch.no_grad():\n",
    "               for inputs, targets in val_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    probabilities = model(inputs)\n",
    "                    all_val_predictions.extend(probabilities.squeeze().cpu().tolist())\n",
    "                    all_val_targets.extend(targets.cpu().tolist())\n",
    "\n",
    "          # Calculate validation metrics\n",
    "          val_auroc = roc_auc_score(all_val_targets, all_val_predictions)\n",
    "          val_auprc = average_precision_score(all_val_targets, all_val_predictions)\n",
    "\n",
    "          # Combine AUROC and AUPRC into a single score (weighted sum)\n",
    "          combined_score = 0.5 * val_auroc + 0.5 * val_auprc  # Adjust weights as needed\n",
    "          best_val_score = max(best_val_score, combined_score)\n",
    "\n",
    "     return best_val_score  # Return the best combined score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "# study = optuna.create_study(direction=\"maximize\")  \n",
    "# study.optimize(objective, n_trials=25)\n",
    "\n",
    "# best_params = study.best_params\n",
    "\n",
    "# # Print the best hyperparameters\n",
    "# print(\"Best hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.3718\n",
      "Epoch [2/10], Loss: 0.3077\n",
      "Epoch [3/10], Loss: 0.2998\n",
      "Epoch [4/10], Loss: 0.2927\n",
      "Epoch [5/10], Loss: 0.2854\n",
      "Epoch [6/10], Loss: 0.2777\n",
      "Epoch [7/10], Loss: 0.2702\n",
      "Epoch [8/10], Loss: 0.2627\n",
      "Epoch [9/10], Loss: 0.2527\n",
      "Epoch [10/10], Loss: 0.2471\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "if bidirectional:\n",
    "    best_params = {\n",
    "        'hidden_size': 256, \n",
    "        'num_layers': 4, \n",
    "        'learning_rate': 5.095326515363872e-05, \n",
    "        'weight_decay': 0.0005569056693796072, \n",
    "        'dropout': 0.17100380863595918\n",
    "    }\n",
    "else:\n",
    "    best_params = {\n",
    "        'hidden_size': 256, \n",
    "        'num_layers': 2, \n",
    "        'learning_rate': 9.892595905291616e-05, \n",
    "        'weight_decay': 1.4600838938197394e-05, \n",
    "        'dropout': 0.18640091013719517\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "model = LSTMClassifier(\n",
    "    input_dim=41, \n",
    "    hidden_size=best_params[\"hidden_size\"], \n",
    "    num_layers=best_params[\"num_layers\"], \n",
    "    num_classes=1, \n",
    "    dropout=best_params[\"dropout\"], \n",
    "    bidirectional=bidirectional\n",
    ").to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=best_params['learning_rate'],\n",
    "    weight_decay=best_params[\"weight_decay\"]\n",
    ")\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AuROC: 0.8270\n",
      "Test AuPRC: 0.4871\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "model.eval()  # Set model to evaluation mode\n",
    "total_loss = 0\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Get probabilities (if using softmax for multi-class or sigmoid for binary)\n",
    "        probs = outputs\n",
    "\n",
    "\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "# Compute metrics\n",
    "average_loss = total_loss / len(test_loader)\n",
    "auroc = roc_auc_score(all_labels, all_probs)\n",
    "auprc = average_precision_score(all_labels, all_probs)\n",
    "\n",
    "print(f\"Test AuROC: {auroc:.4f}\")\n",
    "print(f\"Test AuPRC: {auprc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
